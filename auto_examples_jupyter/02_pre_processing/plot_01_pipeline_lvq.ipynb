{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Pipelines\n",
    "\n",
    "In these examples GMLVQ is used but the same applies to all the other algorithms.\n",
    "Also the `pipelines`_ feature is provided by scikit-learn and we therefore refer to scikit-learn's\n",
    "documentation  for more details.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklvq import GMLVQ\n",
    "\n",
    "data, labels = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous examples we used a StandardScalar instance to process the data before fitting the\n",
    "model. Sklearn provides a very handy way of creating a connection between the scalar and the\n",
    "model called a pipeline. The pipeline can then be used and will first call the fit method of\n",
    "the standard scaler before the fit of the model. Now the data does not have to be scaled\n",
    "explicitly anymore.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a scaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create a GMLVQ model (or any other sklearn compatible estimator or other pre-processing method)\n",
    "model = GMLVQ(\n",
    "    distance_type=\"adaptive-squared-euclidean\",\n",
    "    activation_type=\"swish\",\n",
    "    activation_params={\"beta\": 2},\n",
    "    solver_type=\"waypoint-gradient-descent\",\n",
    "    solver_params={\"max_runs\": 10, \"k\": 3, \"step_size\": np.array([0.1, 0.05])},\n",
    "    random_state=1428,\n",
    ")\n",
    "\n",
    "# Link them together into a single object.\n",
    "pipeline = make_pipeline(scaler, model)\n",
    "\n",
    "# Fit the data to the pipeline. This will first call the scaler's  fit method before passing the\n",
    "# result to  the model's fit function.\n",
    "pipeline.fit(data, labels)\n",
    "\n",
    "# Predict the labels using the trained pipeline. The pipeline will use the\n",
    "# mean and standard deviation it found when fit was called and applies it to the data.\n",
    "predicted_labels = pipeline.predict(data)\n",
    "\n",
    "# Print a classification report (sklearn)\n",
    "print(classification_report(labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When inspecting the resulting classifier and its prototypes,\n",
    "e.g., in a plot overlaid on a scatter plot of the data, don't forget to apply the scaling to the data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "transformed_data = pipeline.transform(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
